# INDO_ML - Complete Project Structure

**Repository**: https://github.com/Kweenbee187/INDO_ML_2025  
**Contributors**: @Kweenbee187 & @tituatgithub  
**Test Results**: Accuracy 87.48% | Macro F1 69.94%

---

## ðŸ“ Directory Structure

```
INDO_ML/
â”‚
â”œâ”€â”€ README.md                          # Main project documentation
â”œâ”€â”€ LICENSE                            # MIT License
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .gitignore                         # Git ignore rules
â”œâ”€â”€ SETUP.md                          # Installation & setup guide
â”œâ”€â”€ CONTRIBUTING.md                    # Contribution guidelines
â”œâ”€â”€ PROJECT_STRUCTURE.md              # This file
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                   # Configuration parameters
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py                   # Package initializer
â”‚   â”œâ”€â”€ train_model.py                # Main training script â­
â”‚   â”œâ”€â”€ model.py                      # Model architecture & trainer
â”‚   â”œâ”€â”€ data_processing.py            # Data loading & preprocessing
â”‚   â””â”€â”€ utils.py                      # Utility functions
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ AI_Tutor_Evaluation.ipynb    # Jupyter notebook walkthrough
â”‚
â”œâ”€â”€ data/                             # Data directory
â”‚   â”œâ”€â”€ README.md                     # Data documentation
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ models/                           # Saved model checkpoints
â”‚   â””â”€â”€ .gitkeep                      # (generated during training)
â”‚
â”œâ”€â”€ outputs/                          # Results & predictions
â”‚   â”œâ”€â”€ predictions/                  # Prediction JSON files
â”‚   â”œâ”€â”€ metrics/                      # Evaluation metrics
â”‚   â””â”€â”€ logs/                         # Training logs
â”‚
â””â”€â”€ docs/                             # Additional documentation
    â”œâ”€â”€ model_architecture.md         # Detailed architecture docs
    â””â”€â”€ results_analysis.md           # Results analysis
```

---

## ðŸ“„ File Descriptions

### Root Files

| File | Description | Size | Essential |
|------|-------------|------|-----------|
| `README.md` | Main project documentation with setup instructions | ~15KB | âœ… Yes |
| `LICENSE` | MIT License for the project | ~1KB | âœ… Yes |
| `requirements.txt` | Python package dependencies | ~500B | âœ… Yes |
| `.gitignore` | Files to exclude from version control | ~1KB | âœ… Yes |
| `SETUP.md` | Detailed setup and troubleshooting guide | ~8KB | â­ Recommended |
| `CONTRIBUTING.md` | Guidelines for contributors | ~6KB | ðŸ“ Optional |
| `PROJECT_STRUCTURE.md` | This file - project structure overview | ~4KB | ðŸ“ Optional |

### Configuration (`config/`)

| File | Description | Purpose |
|------|-------------|---------|
| `config.yaml` | Hyperparameters and model settings | Centralized configuration management |

**Key parameters in config.yaml:**
```yaml
model:
  name: "microsoft/deberta-v3-base"
  max_length: 384

training:
  learning_rate: 3e-5
  batch_size: 16
  num_epochs: 3
  n_folds: 5
```

### Source Code (`src/`)

| File | Lines | Description | Main Functions |
|------|-------|-------------|----------------|
| `train_model.py` | ~400 | Main training pipeline | `train_model()`, `main()` |
| `model.py` | ~350 | Model architecture & trainer | `ResponseDataset`, `WeightedCrossEntropyTrainer`, `compute_metrics()` |
| `data_processing.py` | ~300 | Data loading & preprocessing | `load_training_data()`, `minimal_augment()`, `concat_text()` |
| `utils.py` | ~250 | Utility functions | `set_seed()`, `check_gpu()`, `print_metrics_summary()` |

#### `train_model.py` - Main Training Script

**Purpose**: Complete training pipeline with k-fold cross-validation

**Key Features**:
- 5-fold stratified cross-validation
- Data augmentation for minority class
- Ensemble predictions from all folds
- Comprehensive metrics tracking

**Usage**:
```bash
python src/train_model.py
```

**Output**:
- Trained models for each fold
- Predictions JSON file
- Training logs and metrics

#### `model.py` - Model Architecture

**Purpose**: Define model components and training utilities

**Key Classes**:
- `ResponseDataset`: PyTorch dataset for text data
- `WeightedCrossEntropyTrainer`: Custom trainer with weighted loss
- Metric computation functions

**Example**:
```python
from src.model import ResponseDataset, WeightedCrossEntropyTrainer

dataset = ResponseDataset(texts, labels, tokenizer, max_length=384)
trainer = WeightedCrossEntropyTrainer(model=model, class_weights=weights)
```

#### `data_processing.py` - Data Utilities

**Purpose**: Handle all data loading and preprocessing

**Key Functions**:
- `load_training_data()`: Load and flatten JSON training data
- `load_test_data()`: Load test data
- `minimal_augment()`: Augment minority class samples
- `concat_text()`: Combine conversation history with response
- `encode_labels()`: Convert text labels to integers

**Example**:
```python
from src.data_processing import load_training_data, minimal_augment

df = load_training_data("data/trainset.json")
df_aug = minimal_augment(df, multiplier=2)
```

#### `utils.py` - Utility Functions

**Purpose**: Helper functions for common tasks

**Key Functions**:
- `set_seed()`: Set random seeds for reproducibility
- `check_gpu()`: Check CUDA availability
- `print_metrics_summary()`: Format and print metrics
- `create_output_directory()`: Create directory structure
- `format_time()`: Format seconds to readable time

**Example**:
```python
from src.utils import set_seed, check_gpu, print_metrics_summary

set_seed(42)
check_gpu()
print_metrics_summary(metrics, title="Results")
```

---

## ðŸ”„ Data Flow

```
1. DATA LOADING
   trainset.json â†’ load_training_data() â†’ DataFrame

2. DATA PREPROCESSING
   DataFrame â†’ minimal_augment() â†’ Augmented DataFrame
   â†’ encode_labels() â†’ Encoded labels
   â†’ concat_text() â†’ Preprocessed texts

3. MODEL TRAINING
   texts + labels â†’ ResponseDataset â†’ DataLoader
   â†’ WeightedCrossEntropyTrainer â†’ Trained Model

4. PREDICTION
   test data â†’ Model ensemble â†’ Predictions
   â†’ create_prediction_json() â†’ predictions.json

5. EVALUATION
   predictions + true labels â†’ compute_metrics()
   â†’ Results summary
```

---

## ðŸš€ Quick Start by File

### Step 1: Install Dependencies
```bash
pip install -r requirements.txt
```
**Uses**: `requirements.txt`

### Step 2: Prepare Data
```bash
git clone https://github.com/kaushal0494/UnifyingAITutorEvaluation.git
```
**Output**: Data in `UnifyingAITutorEvaluation/IndoML_Datathon/data/`

### Step 3: Configure Training
**Edit**: `config/config.yaml` (optional)

**Customize**:
- Model name
- Learning rate
- Batch size
- Number of folds

### Step 4: Run Training
```bash
python src/train_model.py
```
**Uses**: 
- `src/train_model.py` (main)
- `src/model.py` (architecture)
- `src/data_processing.py` (data)
- `src/utils.py` (utilities)

**Output**:
- `outputs/predictions/predictions.json`
- `outputs/metrics/*.json`
- `models/fold_*` (model checkpoints)

### Step 5: View Results
Check console output or:
```bash
cat outputs/metrics/summary.json
```

---

## ðŸ“ File Dependencies

### `train_model.py` depends on:
- âœ… `model.py` - Model classes
- âœ… `data_processing.py` - Data loading
- âœ… `utils.py` - Utilities
- âœ… `config/config.yaml` - Configuration (optional)

### `model.py` depends on:
- âœ… `transformers` - Hugging Face models
- âœ… `torch` - PyTorch
- âœ… `sklearn` - Metrics

### `data_processing.py` depends on:
- âœ… `pandas` - DataFrame operations
- âœ… `numpy` - Array operations
- âœ… `sklearn` - Label encoding

### `utils.py` depends on:
- âœ… `torch` - Device management
- âœ… Standard library only

---

## ðŸ”§ Customization Guide

### Change Model Architecture

**File**: `config/config.yaml`
```yaml
model:
  name: "roberta-base"  # Change this
  max_length: 512       # Adjust if needed
```

### Modify Training Parameters

**File**: `config/config.yaml`
```yaml
training:
  learning_rate: 2e-5   # Lower for stability
  batch_size: 8         # Reduce if OOM
  num_epochs: 5         # More epochs
```

### Add Custom Augmentation

**File**: `src/data_processing.py`

Add new augmentation in `minimal_augment()` function:
```python
if multiplier >= 3:
    aug3 = row.copy()
    aug3['response'] = "Perhaps, " + row['response']
    rows.append(aug3.to_dict())
```

### Change Evaluation Metrics

**File**: `src/model.py`

Modify `compute_metrics()` function:
```python
def compute_metrics(pred):
    predictions = np.argmax(pred.predictions, axis=-1)
    labels = pred.label_ids
    
    return {
        "f1_macro": f1_score(labels, predictions, average="macro"),
        "
